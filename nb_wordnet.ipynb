{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NLP Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import sys\n",
    "import spacy\n",
    "\n",
    "# Load NLP\n",
    "#sys.path.append('../')\n",
    "\n",
    "with open('./nlp/nlp.pickle', 'rb') as f:\n",
    "    nlp = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from app.src.helpers.sentence_summarizer import SentenceSummarizer\n",
    "\n",
    "summarizer = SentenceSummarizer(nlp)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Workbench"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val = 'I arrived within 2 weeks of the project being completed.'\n",
    "\n",
    "doc = nlp(val)\n",
    "\n",
    "summarizer.summarize(val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import wordnet as wn "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = wn.synsets('credit_card')\n",
    "\n",
    "f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nl_text = 'credit_card'\n",
    "\n",
    "description = 'the seller shall deliver the goods to the buyer'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_ss_name = 'instrumentality.n.03'\n",
    "target_ss = wn.synset(target_ss_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_synsets = wn.synsets(nl_text, pos=wn.NOUN)\n",
    "\n",
    "\n",
    "for x in all_synsets:\n",
    "    print('\\n')\n",
    "    print(f'{x.name()}: {x.definition()}')\n",
    "    print(x.lemma_names())\n",
    "\n",
    "    h = x.lowest_common_hypernyms(target_ss)\n",
    "    print(h)\n",
    "\n",
    "    #doc1 = nlp(description)\n",
    "    #doc2 = nlp(x.definition())\n",
    "    #sim = doc1.similarity(doc2)\n",
    "    #print(sim)\n",
    "    \n",
    "    # Check if its an instrument\n",
    "\n",
    "    # Check if its related to our domain - can use defn and similarity measures...\n",
    "\n",
    "    # "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ss = wn.synsets('contract')\n",
    "\n",
    "contract_synset = wn.synset('contract.n.01')\n",
    "\n",
    "val = 'before the agreement terminates'\n",
    "doc = nlp(val)\n",
    "\n",
    "# Look for a noun that suggests presence of contract\n",
    "## Noun chunk or Noun?\n",
    "## What if it is qualified?\n",
    "nouns = [x for x in doc if x.pos_ == 'NOUN']\n",
    "\n",
    "\n",
    "noun_scores = []\n",
    "\n",
    "for n in nouns:\n",
    "    print(n.text)\n",
    "    n_ss = wn.synsets(n.text, pos=wn.NOUN)\n",
    "    \n",
    "    nd = max([contract_synset.wup_similarity(ns) for ns in n_ss])\n",
    "    noun_scores.append((n, nd))\n",
    "    #print(n_ss)\n",
    "\n",
    "top_ns = max(noun_scores, key=lambda x: x[1])\n",
    "print(top_ns)\n",
    "\n",
    "if top_ns[1] < 0.7:\n",
    "    print('failed threshold')\n",
    "\n",
    "# Look for dependence on event\n",
    "## Case 1: \n",
    "\n",
    "\n",
    "# Contract event\n",
    "\n",
    "\n",
    "# for syn in ss:\n",
    "#     print(syn.name())\n",
    "#     print(syn.definition())\n",
    "#     print('\\n')\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Contract event\n",
    "- presence of contract\n",
    "- something happening to it - narrow set of verbs\n",
    "\n",
    "examples\n",
    "- termination of contract\n",
    "- contract terminate\n",
    "- the contract terminates\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ss = wn.synsets('van')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ss\n",
    "\n",
    "s = wn.synset('van.n.05')\n",
    "s.definition()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s.hypernyms()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = 'van.n.05'\n",
    "sn = wn.synset(a)\n",
    "for i in range(0,8):\n",
    "    print('-', sn.name(), sn.definition())\n",
    "    sn = sn.hypernyms()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# instrumentality\n",
    "inst_s = wn.synset('instrumentality.n.03')\n",
    "\n",
    "# List some hyponyms\n",
    "# Check for hypnym\n",
    "\n",
    "check = inst_s.hyponyms()\n",
    "#print(check)\n",
    "\n",
    "f = wn.synset('van.n.05')\n",
    "\n",
    "\n",
    "x = inst_s.lowest_common_hypernyms(f)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What do we want\n",
    "# User enters a noun\n",
    "# perform some checks to verify that what they enter is in fact an instrument\n",
    "# Can also do some stripping, e.g of determiners\n",
    "\n",
    "# Take a string - get all noun synsets\n",
    "# Look through these synsets to see if they relate to instrumentality (or see if there are other useful anchor synsets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Main\n",
    "- Input: Piece of text\n",
    "- Output: properly formatted instrument spec\n",
    "\n",
    "Inner\n",
    "- input: noun phrase\n",
    "- output: is it an instrument \n",
    "- or maybe I can soften it - put a probability? Or that could be an internal detail\n",
    "\n",
    "How will we handle noun phrases. Can wordnet do this?\n",
    "\n",
    "Questions\n",
    "- can we handle noun phrases, or just single nouns\n",
    "- this will be a question of certainty - what is the threshold\n",
    "- what is the user experience? Do they get a warning, a simple pass/fail, etc\n",
    "- Should we take into account the specific domain or other parts of the contract\n",
    "\n",
    "For the delivery example\n",
    "- we can check if its an instrument\n",
    "- we can check the relatedness to the obligation/event text\n",
    "\n",
    "Should do a wordnet tutorial"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('sym-env': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c5aa13c5662b7cd49c2a6a4cb6c712880a857c98a831bc049e568d94e5223a76"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
