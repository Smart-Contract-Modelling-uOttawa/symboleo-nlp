{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NLP Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import sys\n",
    "import spacy\n",
    "\n",
    "# Load NLP\n",
    "#sys.path.append('../')\n",
    "\n",
    "with open('./nlp/nlp.pickle', 'rb') as f:\n",
    "    nlp = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "apple pie\n",
      "DocUnit('apple', 'NN', 'compound', 'pie'),\n",
      "DocUnit('pie', 'NN', 'ROOT', 'pie'),\n",
      "\n",
      "\n",
      "bob\n",
      "DocUnit('bob', 'NN', 'ROOT', 'bob'),\n",
      "\n",
      "\n",
      "buyer\n",
      "DocUnit('buyer', 'NN', 'ROOT', 'buyer'),\n",
      "\n",
      "\n",
      "seller\n",
      "DocUnit('seller', 'NN', 'ROOT', 'seller'),\n",
      "\n",
      "\n",
      "renter\n",
      "DocUnit('renter', 'NN', 'ROOT', 'renter'),\n",
      "\n",
      "\n",
      "landlord\n",
      "DocUnit('landlord', 'NN', 'ROOT', 'landlord'),\n",
      "\n",
      "\n",
      "property\n",
      "DocUnit('property', 'NN', 'ROOT', 'property'),\n",
      "\n",
      "\n",
      "the property\n",
      "DocUnit('the', 'DT', 'det', 'property'),\n",
      "DocUnit('property', 'NN', 'ROOT', 'property'),\n",
      "\n",
      "\n",
      "legal proceedings\n",
      "DocUnit('legal', 'JJ', 'amod', 'proceedings'),\n",
      "DocUnit('proceedings', 'NNS', 'ROOT', 'proceedings'),\n",
      "\n",
      "\n",
      "pets\n",
      "DocUnit('pets', 'NNS', 'ROOT', 'pets'),\n",
      "\n",
      "\n",
      "credit card\n",
      "DocUnit('credit', 'NN', 'compound', 'card'),\n",
      "DocUnit('card', 'NN', 'ROOT', 'card'),\n",
      "\n",
      "\n",
      "$100\n",
      "DocUnit('$', '$', 'nmod', '100'),\n",
      "DocUnit('100', 'CD', 'ROOT', '100'),\n",
      "\n",
      "\n",
      "CAD\n",
      "DocUnit('CAD', 'NNP', 'ROOT', 'CAD'),\n",
      "\n",
      "\n",
      "March 30, 2024\n",
      "DocUnit('March', 'NNP', 'ROOT', 'March'),\n",
      "DocUnit('30', 'CD', 'nummod', 'March'),\n",
      "DocUnit(',', ',', 'punct', 'March'),\n",
      "DocUnit('2024', 'CD', 'nummod', 'March'),\n",
      "\n",
      "\n",
      "client\n",
      "DocUnit('client', 'NN', 'ROOT', 'client'),\n",
      "\n",
      "\n",
      "contractor\n",
      "DocUnit('contractor', 'NN', 'ROOT', 'contractor'),\n",
      "\n",
      "\n",
      "services\n",
      "DocUnit('services', 'NNS', 'ROOT', 'services'),\n",
      "\n",
      "\n",
      "disclosure\n",
      "DocUnit('disclosure', 'NN', 'ROOT', 'disclosure'),\n",
      "\n",
      "\n",
      "BOSCH\n",
      "DocUnit('BOSCH', 'NNP', 'ROOT', 'BOSCH'),\n",
      "\n",
      "\n",
      "CLIENT\n",
      "DocUnit('CLIENT', 'NN', 'ROOT', 'CLIENT'),\n",
      "\n",
      "\n",
      "productivity\n",
      "DocUnit('productivity', 'NN', 'ROOT', 'productivity'),\n",
      "\n",
      "\n",
      "authorization\n",
      "DocUnit('authorization', 'NN', 'ROOT', 'authorization'),\n",
      "\n",
      "\n",
      "Dolphin\n",
      "DocUnit('Dolphin', 'NNP', 'ROOT', 'Dolphin'),\n",
      "\n",
      "\n",
      "the original digital photo files\n",
      "DocUnit('the', 'DT', 'det', 'files'),\n",
      "DocUnit('original', 'JJ', 'amod', 'files'),\n",
      "DocUnit('digital', 'JJ', 'amod', 'photo'),\n",
      "DocUnit('photo', 'NN', 'compound', 'files'),\n",
      "DocUnit('files', 'NNS', 'ROOT', 'files'),\n",
      "\n",
      "\n",
      "cisco\n",
      "DocUnit('cisco', 'NN', 'ROOT', 'cisco'),\n",
      "\n",
      "\n",
      "distributor\n",
      "DocUnit('distributor', 'NN', 'ROOT', 'distributor'),\n",
      "\n",
      "\n",
      "any product\n",
      "DocUnit('any', 'DT', 'det', 'product'),\n",
      "DocUnit('product', 'NN', 'ROOT', 'product'),\n",
      "\n",
      "\n",
      "Porex\n",
      "DocUnit('Porex', 'NNP', 'ROOT', 'Porex'),\n",
      "\n",
      "\n",
      "Cerus\n",
      "DocUnit('Cerus', 'NNP', 'ROOT', 'Cerus'),\n",
      "\n",
      "\n",
      "invoice receipt\n",
      "DocUnit('invoice', 'NN', 'compound', 'receipt'),\n",
      "DocUnit('receipt', 'NN', 'ROOT', 'receipt'),\n",
      "\n",
      "\n",
      "Sponsor\n",
      "DocUnit('Sponsor', 'NN', 'ROOT', 'Sponsor'),\n",
      "\n",
      "\n",
      "Stadium\n",
      "DocUnit('Stadium', 'NN', 'ROOT', 'Stadium'),\n",
      "\n",
      "\n",
      "the party\n",
      "DocUnit('the', 'DT', 'det', 'party'),\n",
      "DocUnit('party', 'NN', 'ROOT', 'party'),\n",
      "\n",
      "\n",
      "Prime\n",
      "DocUnit('Prime', 'NNP', 'ROOT', 'Prime'),\n",
      "\n",
      "\n",
      "Shareholder\n",
      "DocUnit('Shareholder', 'NN', 'ROOT', 'Shareholder'),\n",
      "\n",
      "\n",
      "all project components\n",
      "DocUnit('all', 'DT', 'det', 'components'),\n",
      "DocUnit('project', 'NN', 'compound', 'components'),\n",
      "DocUnit('components', 'NNS', 'ROOT', 'components'),\n",
      "\n",
      "\n",
      "partyA\n",
      "DocUnit('partyA', 'NN', 'ROOT', 'partyA'),\n",
      "\n",
      "\n",
      "partyB\n",
      "DocUnit('partyB', 'NN', 'ROOT', 'partyB'),\n",
      "\n",
      "\n",
      "approval\n",
      "DocUnit('approval', 'NN', 'ROOT', 'approval'),\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from app.src.custom_event_extractor.nlp.doc_parser import DocParser, NlpDoc\n",
    "\n",
    "from app.src.custom_event_extractor.noun_phrase.fake_noun_phrase_extractor import FakeNounPhraseExtractor\n",
    "\n",
    "fp = FakeNounPhraseExtractor()\n",
    "\n",
    "dp = DocParser(nlp)\n",
    "\n",
    "def print_doc(doc: NlpDoc):\n",
    "    for x in doc.tokens:\n",
    "        print(f'DocUnit(\\'{x.text}\\', \\'{x.tag}\\', \\'{x.dep}\\', \\'{x.head}\\'),')\n",
    "    print('\\n')\n",
    "\n",
    "\n",
    "for f in fp.get_dict():\n",
    "    print(f)\n",
    "    next_d = dp.parse(f)\n",
    "    print_doc(next_d)\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# dp.parse('apple_pie')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from app.classes.units.input_unit import InputUnit, UnitType\n",
    "from app.classes.operations.user_input import UserInput\n",
    "\n",
    "from app.src.operations.dependency_builder import DependencyBuilder\n",
    "\n",
    "from app.src.custom_event_extractor.custom_event_extractor_builder import CustomEventExtractorBuilder\n",
    "\n",
    "from tests.test_suites.isolated_test_cases.timespan_before_event import test_case\n",
    "\n",
    "deps = DependencyBuilder.build(fake = False)\n",
    "\n",
    "\n",
    "cee = CustomEventExtractorBuilder.build(deps)\n",
    "\n",
    "user_inputs = [\n",
    "    UserInput(UnitType.TIMESPAN),\n",
    "    UserInput(UnitType.TIME_VALUE, '2'),\n",
    "    UserInput(UnitType.TIME_UNIT, 'days'),\n",
    "    UserInput(UnitType.PRIOR_TO, 'prior to'),\n",
    "    UserInput(UnitType.EVENT),\n",
    "    UserInput(UnitType.CUSTOM_EVENT),\n",
    "    UserInput(UnitType.SUBJECT, 'the party'),\n",
    "    UserInput(UnitType.INTRANSITIVE_VERB, 'happening'),\n",
    "]\n",
    "\n",
    "contract = test_case.init_sym\n",
    "\n",
    "result = cee.extract(user_inputs, contract)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from app.src.custom_event_extractor.verb.verb_extractor import VerbExtractor\n",
    "\n",
    "from app.src.custom_event_extractor.nlp.lemmatizer import Lemmatizer\n",
    "from app.src.custom_event_extractor.verb.conjugator import MyConjugator\n",
    "from app.src.custom_event_extractor.verb.conjugator import ML3Conjugator\n",
    "\n",
    "lemmatizer = Lemmatizer(deps.nlp)\n",
    "\n",
    "inner_conjugator = ML3Conjugator(language = 'en')\n",
    "conjugator = MyConjugator(inner_conjugator)\n",
    "\n",
    "verb_extractor = VerbExtractor(lemmatizer, conjugator)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = verb_extractor.extract('happening', contract)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x.verb_types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CCC returns [<VerbType.TRANSITIVE: ('transitive',)>]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'evt_return_product'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "from tests.helpers.test_obj_lib.isolated_test_objects import CustomEvents\n",
    "\n",
    "x= CustomEvents.return_product()\n",
    "\n",
    "x.event_key()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from app.classes.pattern_classes.within_timespan_event import WithinTimespanEvent\n",
    "\n",
    "x = WithinTimespanEvent()\n",
    "\n",
    "x.__val_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'test.start'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from app.src.object_mappers.time_period_mapper import TimePeriod\n",
    "\n",
    "\n",
    "f = TimePeriod('test')\n",
    "\n",
    "f.start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from app.classes.units.all_units import *\n",
    "\n",
    "x = TimespanUnit()\n",
    "\n",
    "y = x.to_json()\n",
    "\n",
    "y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from app.src.norm_update_extractor.handlers.norm_update_handler_dict import NormUpdateHandlerDictBuilder\n",
    "\n",
    "d = NormUpdateHandlerDictBuilder.build()\n",
    "\n",
    "d[type(WithinTimespanEvent())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from app.src.grammar_builder.grammar_builder import GrammarBuilder\n",
    "from app.src.grammar_builder.pattern_tree_builder import PatternTreeBuilder\n",
    "from app.src.grammar_builder.tree_printer import TreePrinter\n",
    "from app.classes.pattern_classes.pattern_class import PatternClass, PatternVariable as PV\n",
    "\n",
    "from app.classes.pattern_classes.within_timespan_event import WithinTimespanEvent\n",
    "\n",
    "ptb = PatternTreeBuilder()\n",
    "\n",
    "class TestClass(PatternClass):\n",
    "    sequence = [PV.WITHIN, PV.TIMESPAN, PV.P_AFTER_W]\n",
    "\n",
    "res = ptb.build(TestClass)\n",
    "\n",
    "tp = TreePrinter()\n",
    "\n",
    "tp.print(res[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from app.classes.units.unit_type import UnitType\n",
    "from app.classes.units.all_units import unit_type_dict\n",
    "\n",
    "f = UnitType.BEFORE\n",
    "print(type(f), isinstance(f, UnitType))\n",
    "\n",
    "ut = UnitType['FROM']\n",
    "\n",
    "print(ut)\n",
    "\n",
    "x = unit_type_dict[ut]\n",
    "\n",
    "print(x)\n",
    "\n",
    "#x = unit_type_dict[]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from app.classes.pattern_classes.all_pattern_classes import *\n",
    "\n",
    "a = [BeforeDate(), BeforeDate()]\n",
    "\n",
    "d_a = []\n",
    "for x in a:\n",
    "    if type(x) not in [type(y) for y in d_a]:\n",
    "        d_a.append(x)\n",
    "\n",
    "print(d_a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from app.classes.grammar.grammar_node import GrammarNode\n",
    "from app.src.grammar_builder.tree_printer import TreePrinter\n",
    "from app.src.grammar_builder.grammar_builder_constructor import GrammarBuilderConstructor\n",
    "from app.classes.pattern_classes.all_pattern_classes import *\n",
    "\n",
    "gb = GrammarBuilderConstructor.construct()\n",
    "\n",
    "test_set = GrammarNode('A', [\n",
    "    GrammarNode('B', [\n",
    "        GrammarNode('C'),\n",
    "    ]),\n",
    "    GrammarNode('D', [\n",
    "        GrammarNode('E'),\n",
    "    ]),\n",
    "])\n",
    "\n",
    "new_tree = GrammarNode('B', [\n",
    "    GrammarNode('F'),\n",
    "])\n",
    "\n",
    "pattern_classes = get_all_pattern_classes()\n",
    "\n",
    "pattern_classes = [\n",
    "    BeforeDate(),\n",
    "    BeforeEvent(),\n",
    "    # AfterDate(),\n",
    "    # WithinTimespanEvent(),\n",
    "    # TimespanBeforeEvent(),\n",
    "]\n",
    "\n",
    "result = gb.build(pattern_classes)\n",
    "\n",
    "\n",
    "#gb._rec_merge(test_set, new_tree)\n",
    "\n",
    "tp = TreePrinter()\n",
    "\n",
    "tp.print(result)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generating Sym"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from app.templates.template_getter import get_template\n",
    "\n",
    "c_id = 'prop'\n",
    "is_raw = True\n",
    "\n",
    "if is_raw:\n",
    "    folder = f'{c_id}/t_raw'\n",
    "    c_id = f'{c_id}_raw'\n",
    "else:\n",
    "    folder = f'{c_id}/t'\n",
    "\n",
    "contract = get_template(c_id)\n",
    "sym_spec = contract.to_sym()\n",
    "\n",
    "FILEPATH = f'./app/templates/{folder}/{c_id}.txt'\n",
    "\n",
    "f = open(FILEPATH, 'w')\n",
    "f.write(sym_spec)\n",
    "f.close()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Bench"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from app.console_lib.sentence_summarizer import SentenceSummarizer\n",
    "\n",
    "summarizer = SentenceSummarizer(nlp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val = 'I arrived within 2 weeks of the project being completed.'\n",
    "\n",
    "doc = nlp(val)\n",
    "\n",
    "summarizer.summarize(val)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('sym-env': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c5aa13c5662b7cd49c2a6a4cb6c712880a857c98a831bc049e568d94e5223a76"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
